import { GoogleGenAI, Modality } from "@google/genai";
import type { Product } from '../types';

// Use Vite client env var; do NOT throw at module import time.
const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY || import.meta.env.API_KEY || '';

let ai: GoogleGenAI | null = null;
if (GEMINI_API_KEY) {
  ai = new GoogleGenAI({ apiKey: GEMINI_API_KEY });
}

export const generateImage = async (prompt: string, engine: 'Standard' | 'Anime' = 'Standard'): Promise<string> => {
  try {
    if (!ai) {
      throw new Error('Gemini API key not configured. Please set VITE_GEMINI_API_KEY in .env.local');
    }
    let finalPrompt: string;

    if (engine === 'Anime') {
      finalPrompt = `High-quality anime art, manga style, vibrant colors, for merchandise (t-shirt, mug). The design should be centered with a transparent or simple background. Subject: ${prompt}`;
    } else {
      finalPrompt = `A high-resolution, professionally designed graphic for merchandise (t-shirt, mug). The design should be centered with a transparent or simple background. Subject: ${prompt}`;
    }

    const response = await ai.models.generateImages({
      model: 'imagen-4.0-generate-001',
      prompt: finalPrompt,
      config: {
        numberOfImages: 1,
        outputMimeType: 'image/png',
        aspectRatio: '1:1',
      },
    });

    if (response.generatedImages && response.generatedImages.length > 0) {
      const base64ImageBytes: string = response.generatedImages[0].image.imageBytes;
      return `data:image/png;base64,${base64ImageBytes}`;
    } else {
      throw new Error("No image was generated by the API.");
    }
  } catch (error) {
    console.error("Error generating image with Gemini API:", error);
    throw new Error("Failed to generate image.");
  }
};

// Helper function to convert an image URL to a base64 string and its MIME type
const urlToBase64 = async (url: string): Promise<{mimeType: string, data: string}> => {
    const response = await fetch(url);
    if (!response.ok) {
        throw new Error(`Failed to fetch image from URL: ${url}`);
    }
    const blob = await response.blob();
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => {
            const dataUrl = reader.result as string;
            const [header, data] = dataUrl.split(',');
            const mimeType = header.match(/:(.*?);/)?.[1] || 'image/png';
            resolve({ mimeType, data });
        };
        reader.onerror = reject;
        reader.readAsDataURL(blob);
    });
};

/**
 * Creates a new product mockup by applying the design to the product image using AI.
 * @param designDataUrl The base64 data URL of the design image.
 * @param product The product details (mockup URL, type, etc.).
 * @returns A promise that resolves to the data URL of the final product mockup image.
 */
export const applyDesignToProduct = async (designDataUrl: string, product: Product): Promise<string> => {
    try {
        if (!ai) {
          throw new Error('Gemini API key not configured. Please set VITE_GEMINI_API_KEY in .env.local');
        }
        // Step 1: Get base64 data for both the mockup and the design.
        const { mimeType: mockupMimeType, data: mockupBase64 } = await urlToBase64(product.mockupUrl);
        const [designHeader, designBase64] = designDataUrl.split(',');
        const designMimeType = designHeader.match(/:(.*?);/)?.[1] || 'image/png';

        // Step 2: Prepare parts for the multimodal prompt.
        const mockupPart = {
            inlineData: {
                mimeType: mockupMimeType,
                data: mockupBase64,
            },
        };

        const designPart = {
            inlineData: {
                mimeType: designMimeType,
                data: designBase64,
            },
        };

        const textPrompt = `Flawlessly place the second image (the design) onto the ${product.printAreaPosition} of the ${product.type} in the first image (the mockup). The design should look realistic, conforming to the product's shape, wrinkles, and lighting. Preserve the original background and mockup quality. Do not add any text or alter the mockup in any other way. The output must be only the final image.`;
        
        // Step 3: Call the Gemini API to merge the images.
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image-preview',
            contents: {
                parts: [
                    mockupPart,
                    designPart,
                    { text: textPrompt },
                ],
            },
            config: {
                responseModalities: [Modality.IMAGE, Modality.TEXT],
            },
        });

        // Step 4: Process the response to find the generated image.
        for (const part of response.candidates[0].content.parts) {
            if (part.inlineData) {
                const base64ImageBytes: string = part.inlineData.data;
                const outputMimeType = part.inlineData.mimeType || 'image/png';
                return `data:${outputMimeType};base64,${base64ImageBytes}`;
            }
        }
        
        throw new Error("Gemini API did not return an image.");

    } catch (error) {
        console.error("Error applying design with Gemini API:", error);
        throw new Error("Failed to apply design to product.");
    }
};